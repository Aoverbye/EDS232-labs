{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Species Distribution Modeling with Bagging \n",
    "Climate change and deforestation are accelerating ecosystem degradation, pushing animal species toward the brink of extinction. Understanding the distribution of animals and the factors that influence their ability to thrive in different environments is critical for conservation efforts. By studying these relationships, biological conservationists can develop informed strategies to protect endangered species and maintain biodiversity across diverse ecosystems.\n",
    "\n",
    "Species are defined by their behavioral, physiological, and ecological attributes, which shape their roles in ecosystems. In turn, ecosystems and their functions are deeply influenced by the species that inhabit them. This reciprocal relationship makes evaluating species' functional diversity and distributions essential for research in biogeography, community ecology, macroevolution, and conservation. Functional diversity is determined by traits such as diet, foraging strata, trophic level, activity cycle, litter size, generation length, habitat breadth, and body mass. These traits influence an animalâ€™s ability to survive and adapt to different climates, playing a crucial role in ecosystem stability.\n",
    "\n",
    "In this lab, we will explore the connections between animal behaviors, functional traits, and species distributions across different climates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Standardizing column names\n",
    "\n",
    "The dataset contains several columns that describe different aspects of bird diets. These column names currently include spaces, colons (:), and special characters, which can make them difficult to work with in code.\n",
    "\n",
    "Load the dataset (BirdTraitData.csv) into a Pandas DataFrame.\n",
    "\n",
    "The 7 column names that start with \"Diet:\" should be renamed to simpler version starting with `Diet_` in a way that conforms with this list of key variables:\n",
    "\n",
    "`AdultBodyMass`, `DietBreadth`, `Diet_Invertebrates`, `Diet_Vertebrates`,`Diet_Fruits`, `Diet_Flowers`, `Diet_Seeds`, `Diet_Plants`, `Diet_Other`, `TrophicLevel`,`ActivityCycle`, `ForagingStratum`, `MigratoryStatus`,`IncubationTime`, `ClutchSize`, `EggLength`, `EggWidth`,`EggMass`, `NestingHabit`,`MaxLongevity`, `Subarid`\n",
    "\n",
    "Then select only that list of 21 key variables. **Print the head of your dataframe.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load csv\n",
    "bird_traits = pd.read_csv('BirdTraitData.csv', encoding='latin1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order', 'Family', 'Genus', 'Species', 'Authority', 'CommonName',\n",
       "       'AdultBodyMass', 'DietBreadth', 'Diet: invertebrates',\n",
       "       'Diet: vertebrates', 'Diet: fruits', 'Diet: flower/nectar/pollen/gums',\n",
       "       'Diet: seeds', 'Diet: other plant materials',\n",
       "       'Diet: scavenge; garbage; carrion; offal; carcasses', 'TrophicLevel',\n",
       "       'ActivityCycle', 'ForagingStratum', 'MigratoryStatus', 'IncubationTime',\n",
       "       'ClutchSize', 'EggLength', 'EggWidth', 'EggMass', 'NestingHabit',\n",
       "       'MaxLongevity', 'Dry', 'Humid', 'Montane', 'Subarid', 'Subhumid',\n",
       "       'Alaotra.Mangoro', 'Amoron.i.Mania', 'Analamanga', 'Analanjirofo',\n",
       "       'Androy', 'Anosy', 'Atsimo.Andrefana', 'Atsimo.Atsinanana',\n",
       "       'Atsinanana', 'Betsiboka', 'Boeny', 'Bongolava', 'DIANA',\n",
       "       'Haute.Matsiatra', 'Ihorombe', 'Itasy', 'Melaky', 'Menabe', 'SAVA',\n",
       "       'Sofia', 'Vakinankaratra', 'Vatovavy.Fitovinany', 'Antananarivo',\n",
       "       'Antsiranana', 'Fianarantsoa', 'Mahajanga', 'Toamasina', 'Toliara',\n",
       "       'References'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_traits.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.str.replace(' ', '_') # Replace spaces with underscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order', 'Family', 'Genus', 'Species', 'Authority', 'CommonName',\n",
       "       'AdultBodyMass', 'DietBreadth', 'Diet_invertebrates',\n",
       "       'Diet_vertebrates', 'Diet_fruits', 'Diet_flowers', 'Diet_seeds',\n",
       "       'Diet_plants', 'Diet_scavenge; garbage; carrion; offal; carcasses',\n",
       "       'TrophicLevel', 'ActivityCycle', 'ForagingStratum', 'MigratoryStatus',\n",
       "       'IncubationTime', 'ClutchSize', 'EggLength', 'EggWidth', 'EggMass',\n",
       "       'NestingHabit', 'MaxLongevity', 'Dry', 'Humid', 'Montane', 'Subarid',\n",
       "       'Subhumid', 'Alaotra.Mangoro', 'Amoron.i.Mania', 'Analamanga',\n",
       "       'Analanjirofo', 'Androy', 'Anosy', 'Atsimo.Andrefana',\n",
       "       'Atsimo.Atsinanana', 'Atsinanana', 'Betsiboka', 'Boeny', 'Bongolava',\n",
       "       'DIANA', 'Haute.Matsiatra', 'Ihorombe', 'Itasy', 'Melaky', 'Menabe',\n",
       "       'SAVA', 'Sofia', 'Vakinankaratra', 'Vatovavy.Fitovinany',\n",
       "       'Antananarivo', 'Antsiranana', 'Fianarantsoa', 'Mahajanga', 'Toamasina',\n",
       "       'Toliara', 'References'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and replace in columns\n",
    "bird_traits.columns = bird_traits.columns.str.replace('Diet: ', 'Diet_')\n",
    "\n",
    "# Rename columns as needed\n",
    "bird_traits = bird_traits.rename(columns={'Diet_flower/nectar/pollen/gums': 'Diet_flowers', 'Diet_other plant materials' : 'Diet_plants', 'Diet: scavenge; garbage; carrion; offal; carcasses' : 'diet_other'})\n",
    "bird_traits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bird_traits = bird_traits.rename(columns={'Diet_flower/nectar/pollen/gums': 'Diet_flowers', 'Diet_other plant materials' : 'Diet_plants', 'Diet_scavenge; garbage; carrion; offal; carcasses' : 'diet_other'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order', 'Family', 'Genus', 'Species', 'Authority', 'CommonName',\n",
       "       'AdultBodyMass', 'DietBreadth', 'Diet_invertebrates',\n",
       "       'Diet_vertebrates', 'Diet_fruits', 'Diet_flowers', 'Diet_seeds',\n",
       "       'Diet_plants', 'diet_other', 'TrophicLevel', 'ActivityCycle',\n",
       "       'ForagingStratum', 'MigratoryStatus', 'IncubationTime', 'ClutchSize',\n",
       "       'EggLength', 'EggWidth', 'EggMass', 'NestingHabit', 'MaxLongevity',\n",
       "       'Dry', 'Humid', 'Montane', 'Subarid', 'Subhumid', 'Alaotra.Mangoro',\n",
       "       'Amoron.i.Mania', 'Analamanga', 'Analanjirofo', 'Androy', 'Anosy',\n",
       "       'Atsimo.Andrefana', 'Atsimo.Atsinanana', 'Atsinanana', 'Betsiboka',\n",
       "       'Boeny', 'Bongolava', 'DIANA', 'Haute.Matsiatra', 'Ihorombe', 'Itasy',\n",
       "       'Melaky', 'Menabe', 'SAVA', 'Sofia', 'Vakinankaratra',\n",
       "       'Vatovavy.Fitovinany', 'Antananarivo', 'Antsiranana', 'Fianarantsoa',\n",
       "       'Mahajanga', 'Toamasina', 'Toliara', 'References'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_traits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bird_traits = bird_traits.loc[:, ['AdultBodyMass', 'DietBreadth', 'Diet_invertebrates', \n",
    "                                  'Diet_vertebrates', 'Diet_fruits', 'Diet_flowers', \n",
    "                                  'Diet_seeds', 'Diet_plants', \n",
    "                                  'diet_other',  \n",
    "                                  'TrophicLevel', 'ActivityCycle', 'ForagingStratum', \n",
    "                                  'MigratoryStatus', 'IncubationTime', 'ClutchSize', \n",
    "                                  'EggLength', 'EggWidth', 'EggMass', 'NestingHabit', \n",
    "                                  'MaxLongevity', 'Subarid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = ['AdultBodyMass', 'DietBreadth', 'Diet_Invertebrates', 'Diet_Vertebrates', 'Diet_Fruits', 'Diet_Flowers', 'Diet_Seeds','Diet_Plants', 'Diet_Other', 'TrophicLevel', 'ActivityCycle', 'ForagingStratum', 'MigratoryStatus', 'IncubationTime','ClutchSize', 'EggLength', 'EggWidth', 'EggMass', 'NestingHabit', 'MaxLongevity', 'Subarid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(bird_traits.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Encode categorical variables\n",
    "In our dataset, some columns contain categorical (non-numeric) data, such as species names or habitat types that need to be converted to numerical representations. Let's use label encoding to assign a unique number to each category in a column.\n",
    "\n",
    "Encode the data using this process:\n",
    "1. Find all categorical columns in df using `.select_dtypes(include=['object'])`\n",
    "2. Loop through each categorical column and apply `LabelEncoder()`\n",
    "3. Replace the original categorical columns with their encoded values.\n",
    "4. Print the head of your dataframe to ensure that labels were in fact encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AdultBodyMass  DietBreadth  Diet_invertebrates  Diet_vertebrates  \\\n",
      "0          138.5            2                   2                 2   \n",
      "1         1050.0            1                   1                 2   \n",
      "2          181.0            2                   2                 2   \n",
      "3          292.0            2                   2                 2   \n",
      "4          511.0            2                   2                 2   \n",
      "\n",
      "   Diet_fruits  Diet_flowers  Diet_seeds  Diet_plants  diet_other  \\\n",
      "0            1             1           1            1           1   \n",
      "1            1             1           1            1           1   \n",
      "2            1             1           1            1           1   \n",
      "3            1             1           1            1           1   \n",
      "4            1             1           1            1           1   \n",
      "\n",
      "   TrophicLevel  ...  ForagingStratum  MigratoryStatus  IncubationTime  \\\n",
      "0             3  ...                3                0            31.0   \n",
      "1             3  ...                3                0            39.5   \n",
      "2             3  ...                3                0            35.0   \n",
      "3             3  ...                3                0            31.0   \n",
      "4             3  ...                4                0            35.5   \n",
      "\n",
      "   ClutchSize  EggLength  EggWidth  EggMass  NestingHabit  MaxLongevity  \\\n",
      "0         3.0       3.85   -999.00   -999.0             2        -999.0   \n",
      "1         2.5      58.50     46.95   -999.0             2        -999.0   \n",
      "2         2.5      38.35     31.90   -999.0             2        -999.0   \n",
      "3         1.5      43.70     35.20     29.1             2        -999.0   \n",
      "4         2.0      54.50     45.00   -999.0             2         144.0   \n",
      "\n",
      "   Subarid  \n",
      "0        1  \n",
      "1        1  \n",
      "2        1  \n",
      "3        1  \n",
      "4        1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary to store encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = bird_traits.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize LabelEncoder and encode each categorical column\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    bird_traits[col] = le.fit_transform(bird_traits[col])\n",
    "    label_encoders[col] = le  # Store the encoder for potential inverse transformation\n",
    "\n",
    "# Print the df\n",
    "print(bird_traits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Defining features, splitting data, and training a bagging classifier\n",
    "Our goal for this analysis is to predict whether a given bird species is present in Subarid climate zones. \n",
    "\n",
    "1. Drop the corresponding variable from the features (X) and define it as the target (y). Then perform the train-test split with 70/30 train/test and a random state of 808.\n",
    "\n",
    "2. Initialize a bagging classifier with 100 trees, `oob_score =True`, `bootstrap = True` and `random_state = 808`.  \n",
    "\n",
    "3. Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9452\n",
      "OOB Score: 0.8817\n"
     ]
    }
   ],
   "source": [
    "# Define features\n",
    "X = bird_traits.drop(columns=[\"Subarid\"])  # Drop target variable from features\n",
    "y = bird_traits[\"Subarid\"]  # Target variable\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=808)\n",
    "\n",
    "# Initialize and train Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(n_estimators=100, oob_score=True, bootstrap=True, random_state=808)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy and OOB score\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"OOB Score: {bagging_clf.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Make predictions and evaluate the model\n",
    "\n",
    "1. Generate predictions\n",
    "- Use the trained bagging model to predict values for the test set (`X_test`).\n",
    "\n",
    "2. Calculate the Out-of-Bag (OOB) Score\n",
    "- The OOB score is an internal validation score computed using samples not included in bootstrapped subsets.\n",
    "\n",
    "3. Compute model accuracy\n",
    "- Print the OOB score and the bagging accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Generate predictions\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Step 2: Calculate model accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Step 3: Retrieve OOB score (already computed in training)\n",
    "oob_score = bagging_clf.oob_score_\n",
    "\n",
    "# Step 4: Print the evaluation metrics\n",
    "print(f\"Out-of-Bag (OOB) Score: {oob_score:.4f}\")\n",
    "print(f\"Test Accuracy Score: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate and plot ROC curve\n",
    "\n",
    "- Use `label=f\"Bagging (AUC = {roc_auc_bagging:.2f})\"` to include the AUC value in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Compute predicted probabilities\n",
    "y_prob = bagging_clf.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (1)\n",
    "\n",
    "# Step 2: Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc_bagging = auc(fpr, tpr)  # Compute AUC\n",
    "\n",
    "# Step 3: Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Bagging (AUC = {roc_auc_bagging:.2f})\", color=\"blue\", lw=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guessing\")  # Diagonal line\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve for Bagging Classifier\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how does the ROC curve look? How does this compare to our classification accuracy metric?  What might be going on? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your anwer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Introducing upsampling\n",
    "\n",
    "The ROC curve indicates that our model is not performing well.  This is a common issue in imbalanced datasets, where one class significantly outnumbers the other. To improve our modelâ€™s ability to correctly classify both groups, we will upsample the minority class so that both classes have equal representation in the training set.\n",
    "\n",
    "**Perform upsampling to balance the dataset**\n",
    "1. Separate the majority and minority classes:\n",
    "- Identify which class (0,1) is underrepresented (the minority class) and which is overrepresented (the majority class). \n",
    "- Separate both the `X_train` data and `y_train` data into all majority class and all minority class sets. \n",
    "2. Apply upsampling:\n",
    "- Use `resample()` to create additional synthetic samples of the minority class *with replacement* until it is the same size as the majority class data. Use a random state of 808. \n",
    "3. Combine the balanced classes:\n",
    "Merge the original majority class with the newly upsampled minority class.\n",
    "4. Shuffle the resampled dataset:\n",
    "- Randomly shuffle the data to ensure the model does not learn any unintended patterns from the order of the data. Use a random state of 808 for shuffling both the resampled X and y training data. \n",
    "5. Print the value counts for the resampled y training data to ensure that the data is balanced. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "\n",
    "majority_class = y_train.value_counts().idxmax()  # Identify majority class (0 or 1)\n",
    "minority_class = y_train.value_counts().idxmin()  # Identify minority class\n",
    "\n",
    "X_train_majority = X_train[y_train == majority_class]\n",
    "X_train_minority = X_train[y_train == minority_class]\n",
    "\n",
    "y_train_majority = y_train[y_train == majority_class]\n",
    "y_train_minority = y_train[y_train == minority_class]\n",
    "\n",
    "# Upsample the minority class\n",
    "\n",
    "X_train_minority_upsampled, y_train_minority_upsampled = resample(\n",
    "    X_train_minority, y_train_minority,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=len(y_train_majority),\n",
    "    random_state=808\n",
    ")\n",
    "\n",
    "# Combine majority and upsampled minority class\n",
    "\n",
    "X_train_balanced = pd.concat([X_train_majority, X_train_minority_upsampled])\n",
    "y_train_balanced = pd.concat([y_train_majority, y_train_minority_upsampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "\n",
    "X_train_balanced, y_train_balanced = resample(\n",
    "    X_train_balanced, y_train_balanced, random_state=808\n",
    ")\n",
    "\n",
    "# Print value counts \n",
    "print(\"Resampled class distribution:\")\n",
    "print(y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Retrain and evaluate model using balanced data\n",
    "\n",
    "Now that we have addressed the class imbalance by upsampling the minority class, we will retrain the bagging classifier on the newly balanced dataset and evaluate its performance. This will help us determine whether handling class imbalance improves model accuracy and its ability to distinguish between classes. Create a bagging model using your balanced data. Use a random state of 808. Print the accuracy and and ROC Curve for this new model with balanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrain the Bagging Classifier with the balanced dataset\n",
    "bagging_clf_balanced = BaggingClassifier(n_estimators=100, oob_score=True, bootstrap=True, random_state=808)\n",
    "bagging_clf_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate accuracy on the test data\n",
    "y_pred_balanced = bagging_clf_balanced.predict(X_test)\n",
    "test_accuracy_balanced = accuracy_score(y_test, y_pred_balanced)\n",
    "\n",
    "# Calculate ROC curve and AUC \n",
    "y_prob_balanced = bagging_clf_balanced.predict_proba(X_test)[:, 1]  \n",
    "fpr_balanced, tpr_balanced, _ = roc_curve(y_test, y_prob_balanced)\n",
    "roc_auc_balanced = auc(fpr_balanced, tpr_balanced)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Test Accuracy (Balanced Model): {test_accuracy_balanced:.4f}\")\n",
    "print(f\"OOB Score (Balanced Model): {bagging_clf_balanced.oob_score_:.4f}\")\n",
    "print(f\"ROC AUC (Balanced Model): {roc_auc_balanced:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_balanced, tpr_balanced, label=f\"Bagging (AUC = {roc_auc_balanced:.2f})\", color=\"green\", lw=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guessing\")\n",
    "plt.xlabel(\"False Positive Rate \")\n",
    "plt.ylabel(\"True Positive Rate \")\n",
    "plt.title(\"ROC Curve for Bagging Classifier (Balanced Data)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did this second model, trained on balanced data, do in comparison to the first on the accuracy and AUC metrics.  How should we interpret those results?  Did the upscaling prove useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Analyzing feature importance with permutation importance\n",
    "\n",
    "Understanding which bird traits contribute the most to our modelâ€™s predictions is crucial for interpreting results. We covered in lecture how the results of ensemble methods are harder to interpret than a single decision tree.  But we do have some tools to do it.  In this step, we will compute permutation importance, which measures the impact of each trait by shuffling its values and observing the effect on model performance. This will help us identify which functional traitsâ€”such as diet, body mass, or habitat breadthâ€”play the biggest role in predicting whether a species is found in a subarid environment.\n",
    "\n",
    "Use `permutation_importance()` to calculate the importance values.  You'll need to pass it the model, the feature and target test data, and an n_repeats value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    bagging_clf_balanced, X_test, y_test, n_repeats=10, random_state=808\n",
    ")\n",
    "\n",
    "#  Extract feature importance values \n",
    "importance_values = result.importances_mean\n",
    "importance_std = result.importances_std\n",
    "\n",
    "# Create DataFrame \n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': importance_values,\n",
    "    'Standard Deviation': importance_std\n",
    "})\n",
    "\n",
    "# Sort the features in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top 10 most important features\n",
    "print(\"Top 10 most important features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], xerr=importance_df['Standard Deviation'], color='skyblue')\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Feature Importance - Permutation Importance\")\n",
    "plt.gca().invert_yaxis()  # Reverse order so the most important feature is at the top\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features are most important in our model of species distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
